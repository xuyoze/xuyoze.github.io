{"meta":{"title":"程序员的博客","subtitle":"来一个BLOG吧!!","description":"C# Java SpringMVC Python","author":"Yoze","url":"http://xuyoze.github.io"},"pages":[{"title":"all-categories","date":"2018-01-02T01:09:59.968Z","updated":"2018-01-02T01:09:59.968Z","comments":false,"path":"all-categories/index.html","permalink":"http://xuyoze.github.io/all-categories/index.html","excerpt":"","text":""},{"title":"all-tags","date":"2018-01-02T01:09:59.970Z","updated":"2018-01-02T01:09:59.970Z","comments":false,"path":"all-tags/index.html","permalink":"http://xuyoze.github.io/all-tags/index.html","excerpt":"","text":""},{"title":"all-archives","date":"2018-01-02T01:09:59.967Z","updated":"2018-01-02T01:09:59.967Z","comments":false,"path":"all-archives/index.html","permalink":"http://xuyoze.github.io/all-archives/index.html","excerpt":"","text":""}],"posts":[{"title":"练习使用scrapy框架抓取图虫图片","slug":"20180101-using-scrapy","date":"2018-01-01T13:14:58.000Z","updated":"2018-01-02T06:45:26.837Z","comments":true,"path":"2018/01/01/20180101-using-scrapy/","link":"","permalink":"http://xuyoze.github.io/2018/01/01/20180101-using-scrapy/","excerpt":"元旦假期，天干物燥，寒风刺骨，不宜外出。黄历上好像是这么说的，嗯， 准没错。 所以在家三天不出屋。。。。 以上都是借口，其实就是懒，就是宅 整好在熟悉一把Python的爬虫框架scrapy。这篇文章不是教程， 只是我在练习过程中出现的一些问题的记录， 如果你想学习scray框架的话,请移步其他网站文章.或者直接查看scrapy官方文档.","text":"元旦假期，天干物燥，寒风刺骨，不宜外出。黄历上好像是这么说的，嗯， 准没错。 所以在家三天不出屋。。。。 以上都是借口，其实就是懒，就是宅 整好在熟悉一把Python的爬虫框架scrapy。这篇文章不是教程， 只是我在练习过程中出现的一些问题的记录， 如果你想学习scray框架的话,请移步其他网站文章.或者直接查看scrapy官方文档. 爬取前准备图虫的相关图片都是按照Tag的方式进行组织的, 所以我们很容易就可以根据标签进行某类图片的爬取。下面是图虫的入口页面图虫入口 爬去入口每个标签或专题页面采用的是JS动态翻页,我们可以通过WEB工具的网络功能,或者fidder查看对应的请求.获得如下接口请求地址:https://tuchong.com/rest/tags/%E8%87%AA%E7%84%B6/posts?page=1&amp;count=20&amp;type=hot 可以看到, 有几个可用的参数: tags page count type 由此我们可以得到分页的接口数据如下图所示这个是列表页的基本数据信息 返回的JSON数据中每个post节点下都有一个images数组,如果数组中有对个值表示,这个是一组套图.因此我们可以根据 images 节点,循环并获取相应的套图。 原图地址分析由于列表页是缩放后的图片, 所以我们只能手动查看并归纳原图文件的路径规则.也许哪一天规则就变了也说不上但是目前还是可用的。 规则如下： 缩略图规则 :https://photo.tuchong.com/+ author_id + /g/ + img_id +.jpg 如:https://photo.tuchong.com/1370833/g/20494979.jpgauthor_id 是图片作者的编号,img_id 是图片编号 原图规则 :https://photo.tuchong.com/+ author_id + /f/ + img_id +.jpg 如:https://photo.tuchong.com/1370833/f/20494979.jpgauthor_id 是图片作者的编号,img_id 是图片编号 代码编写创建爬虫# 创建项目scrapy startproject TuchongProj# 进入项目cd TuchongProj# 创建爬虫scrapy genspider tuchong tuchong.com 相关代码编写tuchong.py 演示代码, 代码未实现翻页,只取了一页数据。 class TuchongSpider(scrapy.Spider): name = 'tuchong' allowed_domains = ['tuchong.com'] # 请求URL构造参数 tag = \"风光\" types = \"hot\" # new order = \"weekly\" page = \"1\" count = \"20\" baseUrl = \"https://tuchong.com/rest/tags/\" start_urls = [baseUrl + tag + \"/posts?page=\" + page + \"&amp;count=\" + count + \"&amp;order=\" + order] # 暂时未做分页功能(循环page) def parse(self, response): posts = json.loads(response.body)['postList'] for post in posts: images = post['images'] for img in images: item = TuchongprojItem() author_id = img['user_id'] img_id = img['img_id'] img_link = \"https://photo.tuchong.com/\" + \\ str(author_id) + \"/f/\" + str(img_id) + \".jpg\" item['authorId'] = author_id item['imageId'] = img_id item['imageLink'] = img_link yield item 我在定义的Item有三个字段， 这里只取了接口JSON数据中的author_id和img_id 按照上面的分析的规则,拼装了图片的大图路径。 Item定义：class TuchongprojItem(scrapy.Item): # define the fields for your item here like: authorId = scrapy.Field() imageId = scrapy.Field() imageLink = scrapy.Field() 接下来就是定义pipeline处理相关数据了class TuchongprojPipeline(ImagesPipeline): def get_media_requests(self, item, info): imglink = item['imageLink'] # print(imglink) yield scrapy.Request(imglink) def item_completed(self, result, item, info): # print(result) # [(True, &#123;'url': 'https://photo.tuchong.com/1660246/f/9281459.jpg', 'path': 'full/e8876e7547c166d58876c3fce547d6819d8bf031.jpg', 'checksum': 'd78e6ba1115ae956878bdc630173ea7a'&#125;)] # 取出图片存放的地址 author_id = item['authorId'] img_id = item['imageId'] patharr = [x[\"path\"] for ok, x in result if ok] path = patharr[0] # 文件重命名(原地址,新地址) os.rename(images_store + path, images_store + \"full/\" + str(author_id) + \"-\" + str(img_id) + \".jpg\") return item 由于要处理图片数据,我们使用scrapy提供ImagesPipeline进行图片处理.重写ImagesPipeline里的两个方法:get_media_requests方法, 主要负责发送图片获取请求, 这里我们将我们拼装的图片大图地址传递给Request进行图片处理. item_completed方法, 这里主要用来对下载回来的图片进行重命名处理. 我们的命名规则是 author_id+&#39;-&#39;+img_id, 这样便于我们进行排序 ^_^ 使用ImagesPipeline 我们需要制定图片的存放地址,同时我们需要启用当前pipeline settings.py# Configure item pipelines# See http://scrapy.readthedocs.org/en/latest/topics/item-pipeline.htmlITEM_PIPELINES = &#123; &apos;TuchongProj.pipelines.TuchongprojPipeline&apos;: 300,&#125;# 爬取图片后图片存放的位置IMAGES_STORE = &quot;F:/_tuchong/fengjing/&quot; 好了, 爬虫差不多了,运行下试试吧! scrapy crawl tuchong 相关问题接口请求不成功或返回的数据为空 UserAgent问题.自定义UserAgent,在settings.py修改UA # Crawl responsibly by identifying yourself (and your website) on the user-agentUSER_AGENT = &apos;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3294.6 Safari/537.36&apos; 请求过快,相应不过来限制并发数,增加延迟时间 # Configure maximum concurrent requests performed by Scrapy (default: 16)CONCURRENT_REQUESTS = 1# Configure a delay for requests for the same website (default: 0)# See http://scrapy.readthedocs.org/en/latest/topics/settings.html#download-delay# See also autothrottle settings and docsDOWNLOAD_DELAY = 5 本机没有图片处理相关库No module named ‘PIL’ 安装Pillow库pip install pillow pillow基本知识 其他自己写爬虫,纯粹就是玩票。我们自己写爬虫，去爬取别人的数据， 尽量将并发降低，不要给站点造成骚扰。如果可以尽量按照爬虫协议来爬取应允的内容。 附 图虫的爬虫协议# Robots.txt file from http://www.tuchong.com# All robots will spider the domainUser-agent: YandexBotDisallow: /User-agent: MJ12botDisallow: /User-agent: PurebotDisallow: /User-agent: psbotDisallow: /User-agent: *Disallow: /admin/Disallow: /api/ 相关学习资料 scrapy文档(CN)","categories":[{"name":"编程","slug":"programming","permalink":"http://xuyoze.github.io/categories/programming/"}],"tags":[{"name":"python","slug":"python","permalink":"http://xuyoze.github.io/tags/python/"},{"name":"scrapy","slug":"scrapy","permalink":"http://xuyoze.github.io/tags/scrapy/"}]},{"title":"写在2017年的最后几天","slug":"the-last-days-of-2017","date":"2017-12-31T04:02:46.000Z","updated":"2018-01-02T01:09:59.955Z","comments":true,"path":"2017/12/31/the-last-days-of-2017/","link":"","permalink":"http://xuyoze.github.io/2017/12/31/the-last-days-of-2017/","excerpt":"转眼又是一年过去，今天是2017的最后一天了，写点东西记录下17年的一些事情。","text":"转眼又是一年过去，今天是2017的最后一天了，写点东西记录下17年的一些事情。 时光匆匆,从来不给人留下后悔的机会. 如果愿意倒是可以在每年的年底来细数下年初的计划，或者说年初的壮志雄心有多少完成了， 有多少没完成，还有多少根本已经就被忘得一干二净了。 hi 马丹，你当年可是做了这些SB决心哦，忘了吧。。卢瑟。。 以上都是扯淡， 因为我是个基本不做计划的人，哈哈。但是我要记录下我的2017都干了啥。 关于跳槽6月份，换了一家新的公司，至于换公司的理由也是和别人一样，说到底是为了钱，说啥为技术，为了理想，为了xxx都是扯淡。作为一个背负了债务的80后房奴，挣钱还债，亚历山大。 这里我也不想吐槽社会对我们这代人的不公，一代都有一代的难处，有啥办法呢！呵呵。。 换家公司继续写代码喽。 玩票17年自学了几门语言，啊， 好几门呢，要不然咋叫玩票呢！！ 据说Golang非常火啊，于是上半年看了一本叫《go web编程》的电子书，还买了一本《Go 程序设计语言》目前该书还在吃灰中。拿beego框架搞了个小玩意。之后就没怎么用过基本的语法都差不多忘光了。哎，感叹时光啊，记性不如以前了。 学习了一个月的Python,基本语法差不多搞清楚了, 然后还用scrapy框架搞了个小爬虫，自然也是玩票性质的，自娱自乐人畜无害。 接着就掉入了java无穷无尽的配置中，为啥这么说呢，写过好多年的C#代码，换到新公司来了新领导，然而新领导的技术倾向性比我这普通程序员还严重， 我也是无Fuck可说。旧的C#项目要求逐步迁移到Java。 不过多吐槽，能力有限无法左右。 也许是中C#的毒太深， 目前仍在适应Java的一些（很多）东西。慢慢来吧。 计划说过了， 我是个没有计划的一类。 种种2017年有一个大会召开了。2017年比特币疯了你知道吗？2017年差点被当成低端人口给清理了，你遇到过吗？2017年有个电影火了你知道是啥吗？2017年有个地方火山爆发了，然后一票媒体集体意淫，有一帮群众疯狂点赞，然后又被批“巨婴”，你可知道？2017年有一其在倭国的凶杀案，牵动了亿万国人的心，你可知晓并评论过？2017年有一批10后的幼儿被无情的伤害了。2017年有一位中年程序员跳楼了。2017年科技界好像跟AI不沾边你就变成了卢瑟。。。。。","categories":[{"name":"生活","slug":"life","permalink":"http://xuyoze.github.io/categories/life/"}],"tags":[{"name":"Jabber","slug":"Jabber","permalink":"http://xuyoze.github.io/tags/Jabber/"}]},{"title":"Git 错误 fatal Pathspec xxx is in submodule","slug":"fatal-Pathspec-xxx-is-in-submodule","date":"2017-12-30T14:19:49.000Z","updated":"2018-01-02T01:09:59.937Z","comments":true,"path":"2017/12/30/fatal-Pathspec-xxx-is-in-submodule/","link":"","permalink":"http://xuyoze.github.io/2017/12/30/fatal-Pathspec-xxx-is-in-submodule/","excerpt":"下午在创建git仓库的时候,有一个文件夹出现了异常,导致上传到 github后只有一个空的文件夹. 而文件夹中无任何文件. 更换机器后,拉取仓储,重新添加文件后试图将文件添加到git报错. fatal: Pathspec &apos;claudia&apos; is in submodule...","text":"下午在创建git仓库的时候,有一个文件夹出现了异常,导致上传到 github后只有一个空的文件夹. 而文件夹中无任何文件. 更换机器后,拉取仓储,重新添加文件后试图将文件添加到git报错. fatal: Pathspec &apos;claudia&apos; is in submodule... 查找网友解决方法,在此记录如下: I have a repository on google code with my project.I use Git source control.It seems that when I try to add files to git from a specific directory, I get the following error:fatal: Pathspec ‘autoload_classmap.php’ is in submodule ‘module/CocktailMakerModule’Now I’m not trying to add a submodule. I’m just trying to add a directory to git!The result that I have now is that this directory is committed empty. So when I try to add specific files I get the above error message.I checked and there isn’t any other .git directory in that directory, so I’m really confused to why this has happened.Best How To :Still no idea how it happened. All documentation I read assumes I have a .git directory there but I don’t.I just did the following:git rm -rf –cached CocktailMakerModule/git add CocktailMakerModule/That seems to resolve the issue. 解决方法: 执行命令从本地仓储删除现有文件夹 git rm -rf --cached claudia/ 添加文件后重新添加到本地仓储 git add claudia/ 问题解决! fatal: Pathspec ‘autoload_classmap.php’ is in submodule ‘module/CocktailMakerModule’ howtobuildsoftware.comfatal: Pathspec...","categories":[{"name":"编程","slug":"programming","permalink":"http://xuyoze.github.io/categories/programming/"}],"tags":[{"name":"git","slug":"git","permalink":"http://xuyoze.github.io/tags/git/"}]},{"title":"目录示例","slug":"topic-demo","date":"2017-12-29T15:30:07.000Z","updated":"2018-01-02T01:09:59.962Z","comments":true,"path":"2017/12/29/topic-demo/","link":"","permalink":"http://xuyoze.github.io/2017/12/29/topic-demo/","excerpt":"这篇文章没有任何意义,只是在联系hexo的一些用法,一记主题的一些配置.使用&lt;!-- excerpt --&gt;表示这里的这一段是引言,在正文中不会再出现.","text":"目录1.1 目录1 列表2.1 目录二 Lorem ipsum dolor sit amet, consectetur adipiscing elit. Fusce eget urna vitae velit eleifend interdum at ac nisi. In nec ligula lacus. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Sed eu cursus erat, ut dapibus quam. Aliquam eleifend dolor vitae libero pharetra adipiscing. Etiam adipiscing dolor a quam tempor, eu convallis nulla varius. Aliquam sollicitudin risus a porta aliquam. Ut nec velit dolor. Proin eget leo lobortis, aliquam est sed, mollis mauris. Fusce vitae leo pretium massa accumsan condimentum. Fusce malesuada gravida lectus vel vulputate. Donec bibendum porta nibh ut aliquam. Sed lorem felis, congue non fringilla eu, aliquam eu eros. Curabitur orci libero, mollis sed semper vitae, adipiscing in lectus. Aenean non egestas odio. Donec sollicitudin nisi quis lorem gravida, in pharetra mauris fringilla. Duis sit amet faucibus dolor, id aliquam neque. In egestas, odio gravida tempor dictum, mauris felis faucibus purus, sit amet commodo lacus diam vitae est. Ut ut quam eget massa semper sodales. Aenean non ipsum cursus, blandit lectus in, ornare odio. Curabitur ultrices porttitor vulputate.Lorem ipsum dolor sit amet, consectetur adipiscing elit. Fusce eget urna vitae velit eleifend interdum at ac nisi. In nec ligula lacus. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Sed eu cursus erat, ut dapibus quam. Aliquam eleifend dolor vitae libero pharetra adipiscing. Etiam adipiscing dolor a quam tempor, eu convallis nulla varius. Aliquam sollicitudin risus a porta aliquam. Ut nec velit dolor. Proin eget leo lobortis, aliquam est sed, mollis mauris. Fusce vitae leo pretium massa accumsan condimentum. Fusce malesuada gravida lectus vel vulputate. Donec bibendum porta nibh ut aliquam. Sed lorem felis, congue non fringilla eu, aliquam eu eros. Curabitur orci libero, mollis sed semper vitae, adipiscing in lectus. Aenean non egestas odio. Donec sollicitudin nisi quis lorem gravida, in pharetra mauris fringilla. Duis sit amet faucibus dolor, id aliquam neque. In egestas, odio gravida tempor dictum, mauris felis faucibus purus, sit amet commodo lacus diam vitae est. Ut ut quam eget massa semper sodales. Aenean non ipsum cursus, blandit lectus in, ornare odio. Curabitur ultrices porttitor vulputate.Lorem ipsum dolor sit amet, consectetur adipiscing elit. Fusce eget urna vitae velit eleifend interdum at ac nisi. In nec ligula lacus. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Sed eu cursus erat, ut dapibus quam. Aliquam eleifend dolor vitae libero pharetra adipiscing. Etiam adipiscing dolor a quam tempor, eu convallis nulla varius. Aliquam sollicitudin risus a porta aliquam. Ut nec velit dolor. Proin eget leo lobortis, aliquam est sed, mollis mauris. Fusce vitae leo pretium massa accumsan condimentum. Fusce malesuada gravida lectus vel vulputate. Donec bibendum porta nibh ut aliquam. Sed lorem felis, congue non fringilla eu, aliquam5 eu eros. Curabitur orci libero, mollis sed semper vitae, adipiscing in lectus. Aenean non egestas odio. Donec sollicitudin nisi quis lorem gravida, in pharetra mauris fringilla. Duis sit amet faucibus dolor, id aliquam neque. In egestas, odio gravida tempor dictum, mauris felis faucibus purus, sit amet commodo lacus diam vitae est. Ut ut quam eget massa semper sodales. Aenean non ipsum cursus, blandit lectus in, ornare odio. Curabitur ultrices porttitor vulputate.","categories":[{"name":"HEXO","slug":"HEXO","permalink":"http://xuyoze.github.io/categories/HEXO/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://xuyoze.github.io/tags/hexo/"}]},{"title":"相册示例","slug":"gallrey-demo","date":"2017-12-29T15:21:04.000Z","updated":"2018-01-02T01:09:59.942Z","comments":true,"path":"2017/12/29/gallrey-demo/","link":"","permalink":"http://xuyoze.github.io/2017/12/29/gallrey-demo/","excerpt":"这篇文章没有任何意义,只是在联系hexo相册的一些用法.","text":"这篇文章没有任何意义,只是在联系hexo相册的一些用法.","categories":[{"name":"HEXO","slug":"HEXO","permalink":"http://xuyoze.github.io/categories/HEXO/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://xuyoze.github.io/tags/hexo/"}]},{"title":"HEXO 中的一些常用方法","slug":"about-hexo","date":"2017-12-29T12:37:26.000Z","updated":"2018-01-02T01:09:59.916Z","comments":true,"path":"2017/12/29/about-hexo/","link":"","permalink":"http://xuyoze.github.io/2017/12/29/about-hexo/","excerpt":"这篇文章没有任何意义,只是在联系hexo的一些用法,一记主题的一些配置.","text":"这篇文章没有任何意义,只是在联系hexo的一些用法,一记主题的一些配置. 关于目录使用关键标签&lt;!-- toc --&gt;,可以在指定的地方自动生成目录. 图片引入 文字高亮&#123;% hl_text [(classes | hexa code | rgb color | rgba color)] %&#125; content&#123;% endhl_text %&#125; Verizon首席网络工程师兼无线网络负责人Nicola Palmern说：“大规模MIMO是4G LTE的重要组成部分，并将在5G技术中发挥重要作用，可以降低数十亿个连接中的单位数延迟以及提高他们的可扩展性。”MIMO，多输入多输出技术（Multiple-Input Multiple-Output）是指在发射端和接收端分别使用多个发射天线和接收天线，使信号通过发射端与接收端的多个天线传送和接收，从而改善通信质量。这项技术现在使用得最多的是家庭Wi-Fi网络，类型通常是2×2或3×3的天线，即用于发送和接收的两个或三个天线。大规模MIMO采用相同的概念，并将其变成一路。## 特殊提示框&#123;% alert [classes] %&#125;content&#123;% endalert %&#125; Verizon没有说明测试使用了多少个天线，但是大规模MIMO通常意味着比现有技术高几个数量级。 Verizon没有说明测试使用了多少个天线，但是大规模MIMO通常意味着比现有技术高几个数量级。 Verizon没有说明测试使用了多少个天线，但是大规模MIMO通常意味着比现有技术高几个数量级。 Verizon没有说明测试使用了多少个天线，但是大规模MIMO通常意味着比现有技术高几个数量级。 Verizon没有说明测试使用了多少个天线，但是大规模MIMO通常意味着比现有技术高几个数量级。 文字引用块 hexo 关于引用块的文档引用块标签 普通引用Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque hendrerit lacus ut purus iaculis feugiat. Sed nec tempor elit, quis aliquam neque. Curabitur sed diam eget dolor fermentum semper at eu lorem. 引用书上的句子Do not just seek happiness for yourself. Seek happiness for all. Through kindness. Through mercy. David LevithanWide Awake 引用 TwitterNEW: DevDocs now comes with syntax highlighting. http://devdocs.io @DevDocstwitter.com/devdocs/status/356095192085962752 引用网络上的文章Every interaction is both precious and an opportunity to delight. Seth GodinWelcome to Island Marketing 图片标签&#123;% image [classes] [group:group-name] /path/to/image [/path/to/thumbnail] [width of thumbnail] [height of thumbnail] [title text] %&#125; classes: fancybox : Generate a fancybox image. nocaption : Caption of the image will not be displayed. left : Image will float at the left. right : Image will float at the right. center : Image will be at center. fig-20 : Image will take 20% of the width of post width and automatically float at left. fig-25 : Image will take 25% of the width of post width and automatically float at left. fig-33 : Image will take 33% of the width of post width and automatically float at left. fig-50 : Image will take 50% of the width of post width and automatically float at left. fig-75 : Image will take 75% of the width of post width and automatically float at left. fig-100 : Image will take 100% of the width of post width. clear : Add a div with clear:both; style attached after the image to retrieve the normal flow of the post. 左右样式 添加fancybox和groups:[xxx] 来组成相册","categories":[{"name":"编程","slug":"programming","permalink":"http://xuyoze.github.io/categories/programming/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://xuyoze.github.io/tags/hexo/"}]},{"title":"你好世界","slug":"hello","date":"2017-12-28T16:00:00.000Z","updated":"2018-01-02T01:09:59.950Z","comments":true,"path":"2017/12/29/hello/","link":"","permalink":"http://xuyoze.github.io/2017/12/29/hello/","excerpt":"2017年最有一个工作日了!!! 午饭时间准备折腾下githubpage.网上找了些教程,想在我这WIN7的机器上安装个jekyll可是这玩意需要ruby运行环境….","text":"2017年最有一个工作日了!!! 午饭时间准备折腾下githubpage.网上找了些教程,想在我这WIN7的机器上安装个jekyll可是这玩意需要ruby运行环境…. 作为一个码猴, 我的8G破车已经无法再来一个运行环境啦!! Nodejs .Net Java Python Golang … 嗯…, 我装这么多也只是玩票啊…哈哈,但是我真的不想在装一个ruby了… 使用 HEXO 为啥用hexo?? 搜索引擎关键字匹配的, 其实我本来并不知道的.. 官网看了下还不错哦 hexi ,感谢这位台湾的小哥. 另外找了一片普及文章, 照着一步步就搞定了.(画瓢我还是可以的) 接下来就是选个模板啥的, 这些都可以按照hexo官方文档来做. 然后我就码了这个小文… 接着折腾去了 我闪~ 参考文章 官方文档 主题 通过Hexo在Github上搭建博客教程","categories":[],"tags":[{"name":"Jabber","slug":"Jabber","permalink":"http://xuyoze.github.io/tags/Jabber/"}]}]}